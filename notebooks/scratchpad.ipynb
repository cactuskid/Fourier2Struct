{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notbook is for testing out little bits of code that could be useful in the overall pipeline. API calls, reading alignments, running other software stuff etc\n",
    "#I've added some comments in cells for some small tasks we might need to do often. It would be good to have some sanity check outputs for each task to make sure the code is working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup folders\n",
    "import os\n",
    "import glob\n",
    "folders = [ 'alns' , 'templates' , 'TensorflowModels' ]\n",
    "clear = False\n",
    "\n",
    "for path in folders:\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    if clear == True:\n",
    "        files = glob.glob(path+'*.pdb')\n",
    "        for f in files:\n",
    "            os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl pdb files\n",
    "#this uses wget to download individual pdb files and stores the paths\n",
    "import wget\n",
    "dl_url = 'http://files.rcsb.org/download/'\n",
    "dl_url_err = 'http://files.rcsb.org/download/'\n",
    "structs = {}\n",
    "already = glob.glob( './templates/*.pdb' )\n",
    "print(already)\n",
    "#pull complexes\n",
    "for m in models:\n",
    "    structfile = './templates/'+m.upper().strip()+'.pdb'\n",
    "    if structfile not in already:\n",
    "        print(m)\n",
    "        time.sleep(1)\n",
    "        try:\n",
    "            wget.download(url = dl_url + m.strip() +'.pdb' , out =structfile)\n",
    "            structs[m] = structfile\n",
    "        except:\n",
    "            try:\n",
    "                wget.download(url = dl_url + m.strip() +'.pdb' , out =structfile)\n",
    "                structs[m] = structfile\n",
    "            except:\n",
    "                print('err', m )\n",
    "    else:\n",
    "        structs[m.strip()] = structfile\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'structs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-32eb52878520>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mstructseqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'structs.fast'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;32mas\u001b[0m \u001b[0mfastout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstructs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mStructure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDBParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mStructure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'structs' is not defined"
     ]
    }
   ],
   "source": [
    "#grab sequences in AA from the PDB files \n",
    "\n",
    "\n",
    "from Bio import Alphabet\n",
    "from Bio.SeqUtils import seq1\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "\n",
    "parser = PDBParser()\n",
    "#converter from 3 letter codes to 1 letter\n",
    "letter3 = Alphabet.ThreeLetterProtein.letters\n",
    "converter = { l.upper(): seq1(l) for l in letter3 }\n",
    "\n",
    "structseqs={}\n",
    "with open( 'structs.fast' , 'w')as fastout:\n",
    "    for s in structs:\n",
    "        Structure = PDBParser().get_structure(s, structs[s])\n",
    "        for model in Structure:\n",
    "            for chain in model:\n",
    "                res = chain.get_residues()\n",
    "                seq =  ''.join([ converter[r.get_resname()] for r in res if r.get_resname() in converter ] )\n",
    "                fastout.write('>' + s + '|'+ chain.id +'\\n')\n",
    "                fastout.write(str( seq ) +'\\n'  )\n",
    "                structseqs[ s + '|'+ chain.id ] = seq\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#proto for a function that opens an external program. pretty useful since we're using a lot of 3rd party tools\n",
    "\n",
    "import subprocess \n",
    "import shlex\n",
    "\n",
    "def runclustalo( aln , name, path = 'clsutalo' , outdir='./', verbose = False, SS = False):\n",
    "    if verbose == True:\n",
    "        print( [aln , name, path , outdir] )\n",
    "    outhhm= outdir+name+\".hhm\"\n",
    "    args = path + ' -i '+  aln  +' -o '+ outhhm + ' -M 50'\n",
    "    if SS == True:\n",
    "        #todo : make ss prediction here\n",
    "        pass\n",
    "    args = shlex.split(args)\n",
    "    print(args)\n",
    "    p = subprocess.Popen(args )\n",
    "    return p , [outhhm]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the amino acid sequence from the 3d structure to an aligment\n",
    "# run clustalo merge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read aln 2 numpy matrix\n",
    "import numpy\n",
    "from Bio import AlignIO\n",
    "\n",
    "alnfile = ''\n",
    "msa = AlignIO.read(alnfile , format = 'fasta')\n",
    "align_array = np.array([ list(rec.upper())  for rec in msa], np.character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run dssp on a struct\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run protFet on a sequence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdb 2 distmat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fft ndim\n",
    "\n",
    "\n",
    "\n",
    "#Ndimensional robust scaler\n",
    "\n",
    "\n",
    "class NDSRobust(TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self._scaler = RobustScaler(copy=True, **kwargs)\n",
    "        self._orig_shape = None\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        # Save the original shape to reshape the flattened X later\n",
    "        # back to its original shape\n",
    "        \n",
    "        if len(X.shape) > 1:\n",
    "            self._orig_shape = X.shape[1:]\n",
    "        X = self._flatten(X)\n",
    "        self._scaler.fit(X, **kwargs)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.transform(X, **kwargs)\n",
    "        X = self._reshape(X)\n",
    "        return X\n",
    "    \n",
    "    def inverse_transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.inverse_transform(X, **kwargs)\n",
    "        X = self._reshape(X)\n",
    "        return X\n",
    "    \n",
    "    def _flatten(self, X):\n",
    "        # Reshape X to <= 2 dimensions\n",
    "        if len(X.shape) > 2:\n",
    "            n_dims = np.prod(self._orig_shape)\n",
    "            X = X.reshape(-1, n_dims)\n",
    "        return X\n",
    "\n",
    "    def _reshape(self, X):\n",
    "        # Reshape X back to it's original shape\n",
    "        if len(X.shape) >= 2:\n",
    "            X = X.reshape(-1, *self._orig_shape)\n",
    "        return X\n",
    "\n",
    "\n",
    "    \n",
    "class NDSPCA(TransformerMixin):\n",
    "    def __init__(self, **kwargs):\n",
    "        self._scaler = PCA(copy = True, **kwargs)\n",
    "        self._orig_shape = None\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        # Save the original shape to reshape the flattened X later\n",
    "        # back to its original shape\n",
    "        \n",
    "        if len(X.shape) > 1:\n",
    "            self._orig_shape = X.shape[1:]\n",
    "        X = self._flatten(X)\n",
    "        self._scaler.fit(X, **kwargs)\n",
    "        self.explained_variance_ratio_ = self._scaler.explained_variance_ratio_\n",
    "        self.components_ =self._scaler.components_\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.transform(X, **kwargs)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def inverse_transform(self, X, **kwargs):\n",
    "        X = np.array(X)\n",
    "        X = self._flatten(X)\n",
    "        X = self._scaler.inverse_transform(X, **kwargs)\n",
    "        X = self._reshape(X)\n",
    "        return X\n",
    "\n",
    "    def _flatten(self, X):\n",
    "        # Reshape X to <= 2 dimensions\n",
    "        if len(X.shape) > 2:\n",
    "            n_dims = np.prod(self._orig_shape)\n",
    "            X = X.reshape(-1, n_dims)\n",
    "        return X\n",
    "\n",
    "    def _reshape(self, X):\n",
    "        # Reshape X back to it's original shape\n",
    "        if len(X.shape) >= 2:\n",
    "            X = X.reshape(-1, *self._orig_shape)\n",
    "        return X\n",
    "    \n",
    "\n",
    "def fit_y( y , components = 300 , FFT = False ):\n",
    "    if FFT == True:\n",
    "        y = np.stack([ np.fft.rfft2(y[i,:,:]) for i in range(y.shape[0])] )\n",
    "        print(y.shape)\n",
    "        y =  np.hstack( [ np.real(y) , np.imag(y)]  )\n",
    "    print(y.shape)\n",
    "    ndpca = NDSPCA(n_components=components)\n",
    "    ndpca.fit(y)\n",
    "    print('explained variance')\n",
    "    print(np.sum(ndpca.explained_variance_ratio_))\n",
    "    y = ndpca.transform(y)\n",
    "    scaler0 = RobustScaler( )\n",
    "    scaler0.fit(y)\n",
    "    return scaler0, ndpca \n",
    "\n",
    "def transform_y( y, scaler,ndpca , FFT = False ):\n",
    "    if FFT == True:\n",
    "        y = np.stack([ np.fft.rfft2(y[i,:,:]) for i in range(y.shape[0])] )\n",
    "        print(y.shape)\n",
    "        y =  np.hstack( [ np.real(y) , np.imag(y)]  )\n",
    "    y = ndpca.transform(y)\n",
    "    print(y.shape)\n",
    "    y = scaler0.transform(y)\n",
    "    \n",
    "    return y \n",
    "\n",
    "def inverse_transform_y( y , scaler, ndpca , FFT=False):\n",
    "    \n",
    "    y = scaler0.inverse_transform(y)\n",
    "    y = ndpca.inverse_transform(y)\n",
    "\n",
    "    if FFT == True:\n",
    "        split = int(y.shape[1]/2)\n",
    "        y = np.stack([ np.fft.irfft2(y[i,:split,:] + 1j*y[i,split:,:]) for i in range(y.shape[0]) ] )\n",
    "                  \n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
